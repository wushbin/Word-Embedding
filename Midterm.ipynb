{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## import the matrix from co_occur.csv\n",
    "Matrix = np.loadtxt(open(\"./co_occur.csv\", \"rb\"), delimiter=\",\")\n",
    "## import the word dict\n",
    "with open('./dictionary.txt') as file:\n",
    "    content = file.readlines()\n",
    "word_dict = [x.strip() for x in content]\n",
    "word_index = {}\n",
    "for index, word in enumerate(word_dict):\n",
    "    word_index[word] = index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Vector Representation: PPMI \n",
    "Add 2 smooth PPMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Matrix_pmi = Matrix + 2\n",
    "Matrix_sum = np.sum(Matrix_pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P_ij = (Matrix_pmi) / Matrix_sum\n",
    "P_w = (np.sum(Matrix_pmi, axis = 1).reshape(Matrix_pmi.shape[0], 1)) / Matrix_sum \n",
    "P_c = (np.sum(Matrix_pmi, axis = 0).reshape(1, Matrix_pmi.shape[1])) / Matrix_sum \n",
    "pmi = np.log2(P_ij / np.dot(P_w, P_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pmi[pmi < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cosine similarity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vdot([2,0,0], [1,6,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ppmi_cosine(str_input):\n",
    "    idx = word_index[str_input]\n",
    "    similarities = []\n",
    "    input_norm = np.linalg.norm(pmi[idx,:])\n",
    "    ## get the cosine value of input string with all other words \n",
    "    for j in range(pmi.shape[0]):\n",
    "        similarities.append(np.vdot(pmi[idx,:], pmi[j,:]) / (input_norm * np.linalg.norm(pmi[j,:])))\n",
    "    similarities_sorted = np.argsort(similarities)\n",
    "    largest10 = similarities_sorted[-10 :]\n",
    "    return largest10[::-1] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": top 10 most similar: \n",
      "['walk', 'walking', 'walks', 'walked', 'climb', 'swim', 'ride', 'throw', 'sit', 'wait']\n"
     ]
    }
   ],
   "source": [
    "output = ppmi_cosine('walk')\n",
    "print(': ' + 'top 10 most similar: ')   \n",
    "print([word_dict[index] for index in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pmi_analogy_analysis(s1, s2, t1):\n",
    "    existed = [s1,s2,t1]\n",
    "    v_analogy = pmi[word_index[s2],:] - pmi[word_index[s1], :] + pmi[word_index[t1],:]\n",
    "    similarities = []\n",
    "    input_norm = np.linalg.norm(v_analogy)\n",
    "    for j in range(pmi.shape[0]):\n",
    "        similarities.append(np.vdot(v_analogy, pmi[j,:]) / (input_norm * np.linalg.norm(pmi[j,:])))\n",
    "    similarities_sorted = np.argsort(similarities)\n",
    "    largest10 = similarities_sorted[-10:]\n",
    "    candidates = [word_dict[index] for index in largest10[::-1]]\n",
    "    for candidate in candidates:\n",
    "        if not (candidate in existed):\n",
    "            return candidate\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analogy(s1, s2, t1):   \n",
    "    output = pmi_analogy_analysis(s1, s2, t1)\n",
    "    print('\\'' + s1 + ' to ' + s2 + '\\'' + ' is similar as ' + '\\''+ t1 + ' to ' + output + '\\'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy('man', 'woman', 'king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./analogy_task.txt') as file:\n",
    "    analogy_list = [[word.rstrip('\\n') for word in line.split(' ')] for line in file]\n",
    "count = 0\n",
    "for analogy in analogy_list:\n",
    "    output = pmi_analogy_analysis(analogy[0], analogy[1], analogy[2])\n",
    "    if output == analogy[3]:\n",
    "        count += 1\n",
    "print('accuracy: ' + str(count / len(analogy_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(analogy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Vector Representation: SVD Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = np.log(1 + Matrix)\n",
    "W, s, C = np.linalg.svd(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbIAAAGPCAYAAAA5l1VvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1836bff60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize = (6,6), dpi = 80)\n",
    "plt.plot(s.reshape(10000,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a low-rank approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_k = np.diag(s[:100])\n",
    "W_k = W[:,: 100]\n",
    "C_k = C[: 100,:]\n",
    "M_k = np.dot(np.dot(W_k, s_k), C_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_k.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interested = [0,1,2,3,4]\n",
    "for index in interested:\n",
    "    vector = W[:, index]\n",
    "    vector_sorted = np.argsort(vector)\n",
    "    largest10 = vector_sorted[-10:]\n",
    "    smallest10 = vector_sorted[:10]\n",
    "    print('-' * 4 + \"Vector \" + str(index) + ':')\n",
    "    print('top 10 most relevant: ' )   \n",
    "    print([word_dict[index] for index in largest10[::-1]])\n",
    "    print('top 10 least relevant:' )\n",
    "    print([word_dict[index] for index in smallest10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization\n",
    "we can regard the rows of W_normalized as word embeding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2norm_W = np.sqrt((W * W).sum(axis=1))\n",
    "W_normalized =  W / l2norm_W.reshape(W.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2norm_Wk = np.sqrt((W_k * W_k).sum(axis=1))\n",
    "Wk_normalized =  W_k / l2norm_Wk.reshape(W_k.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 'woman'\n",
    "v_woman = Wk_normalized[word_index['woman']]\n",
    "## 'man'\n",
    "v_man = Wk_normalized[word_index['man']]\n",
    "## v1 - v2\n",
    "v_wm = v_woman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_list = ['boy', 'girl', 'brother', 'sister', 'king', 'queen', 'he', 'she', 'john', 'mary', 'wall', 'tree']\n",
    "project_list = []\n",
    "for word in test_list:\n",
    "    v_test = Wk_normalized[word_index[word]]\n",
    "    projection = np.vdot(v_test, v_wm)\n",
    "    project_list.append(projection)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize = (8,8), dpi = 80)\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(project_list, 'ro')\n",
    "for index, value in enumerate(project_list):\n",
    "    ax.annotate('(%s, %s)' %(test_list[index],value), xy=(index,value), textcoords='data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_list2 = ['math', 'history', 'nurse', 'doctor', 'pilot', \n",
    "             'teacher', 'engineer', 'science', 'arts', 'literature', 'bob', 'alice']\n",
    "project_list2 = []\n",
    "for word in test_list2:\n",
    "    v_test = Wk_normalized[word_index[word]]\n",
    "    project = np.vdot(v_test, v_wm)\n",
    "    project_list2.append(project)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize = (8,8), dpi = 80)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.plot(project_list2, 'bo')\n",
    "for index, value in enumerate(project_list2):\n",
    "    ax.annotate('(%s, %s)' %(test_list2[index],value), xy=(index, value), textcoords='data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### similarity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Matrix_similarity = np.dot(Wk_normalized, Wk_normalized.transpose()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = word_index['good']\n",
    "temp_vector = Matrix_similarity[index, :]\n",
    "vector_sorted = np.argsort(temp_vector)\n",
    "largest10 = vector_sorted[-10 :]\n",
    "print(': ' + 'top 10 most similar:' + '-' * 4 )   \n",
    "print([word_dict[index] for index in largest10[::-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svd_similar(str_input):\n",
    "    index = word_index[str_input]\n",
    "    similarities = []\n",
    "    for j in range(Wk_normalized.shape[0]):\n",
    "        similarities.append(np.vdot(Wk_normalized[index,:], Wk_normalized[j,:]))\n",
    "    vector_sorted = np.argsort(similarities)\n",
    "    largest10 = vector_sorted[-10 :]\n",
    "    print(str_input +': ' + 'top 10 most similar:' + '-' * 4 )   \n",
    "    print([word_dict[index] for index in largest10[::-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sister: top 10 most similar:----\n",
      "['sister', 'daughter', 'mother', 'wife', 'aunt', 'daughters', 'grandmother', 'niece', 'sisters', 'cousin']\n"
     ]
    }
   ],
   "source": [
    "svd_similar('sister')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### “man is to woman as king is to __”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['women', 'king', 'queen', 'crown', 'alexander']\n"
     ]
    }
   ],
   "source": [
    "v_mwk = Wk_normalized[word_index['women'],:] - Wk_normalized[word_index['man'], :] + Wk_normalized[word_index['king'],:]\n",
    "from scipy import spatial\n",
    "tree = spatial.KDTree(Wk_normalized)\n",
    "list_search = tree.query(v_mwk, k = 5)\n",
    "print([word_dict[index] for index in list_search[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## s1: france\n",
    "## s2: paris\n",
    "## t1: italy\n",
    "from scipy import spatial\n",
    "def analogy_analysis(s1, s2, t1):\n",
    "    existed = [s1,s2,t1]\n",
    "    v_analogy = Wk_normalized[word_index[s2],:] - Wk_normalized[word_index[s1], :] + Wk_normalized[word_index[t1],:]\n",
    "    tree = spatial.KDTree(Wk_normalized)\n",
    "    list_search = tree.query(v_analogy, k = 10)\n",
    "    candidates = [word_dict[index] for index in list_search[1]]\n",
    "    for candidate in candidates:\n",
    "        if not (candidate in existed):\n",
    "            return candidate\n",
    "    print('no found')\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bangkok'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy_analysis('china', 'shanghai', 'thailand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5498657117278425\n"
     ]
    }
   ],
   "source": [
    "with open('./analogy_task.txt') as file:\n",
    "    analogy_list = [[word.rstrip('\\n') for word in line.split(' ')] for line in file]\n",
    "count = 0\n",
    "for analogy in analogy_list:\n",
    "    output = analogy_analysis(analogy[0], analogy[1], analogy[2])\n",
    "    if output == analogy[3]:\n",
    "        count += 1\n",
    "print('accuracy: ' + str(count / len(analogy_list)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp-env]",
   "language": "python",
   "name": "conda-env-nlp-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
